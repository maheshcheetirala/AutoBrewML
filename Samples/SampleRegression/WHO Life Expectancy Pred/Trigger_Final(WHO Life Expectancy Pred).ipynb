{"cells":[{"cell_type":"markdown","source":["**PROBLEM STATEMENT**\n<br/>Predict the Life Expectancy of countries depending on the social/economic/health factors taken between the years 2000-2015.\n<br/>Get Sample data from Source- https://www.kaggle.com/kumarajarshi/life-expectancy-who\n<br/>\n<br/>**COLUMN DEFINITION**\n<br/>'Country'-Country where record taken\n<br/>,'Year'-Year when record taken 2000-2015 i.e. 15 yrs data. Each years data for all countries, ie 16 records per country\n<br/>,'Status'-Developed or Developing status, skewed towards Developing\n<br/>,'Life expectancy '-Life Expectancy in age or age till when people live, maximum people in bucket of 70-80 yrs age group\n<br/>,'Adult Mortality'-Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years) (out of per 1000 population)\n<br/>,'infant deaths'-Number of Infant Deaths (out of per 1000 population)\n<br/>,'Alcohol'-Alcohol consumption in litres recorded per capita (15+) consumption \n<br/>,'percentage expenditure'-Expenditure on health as a percentage of Gross Domestic Product per capita(%)-??? percentage then how come value in thousand ranges\n<br/>,'Hepatitis B'-Hepatitis B immunization coverage among 1-year-olds (out of 100%)\n<br/>,'Measles '-number of reported cases (out of per 1000 population)\n<br/>,' BMI '-Average Body Mass Index of entire population\n<br/>,'under-five deaths '-Number of under five yrs age deaths (out of per 1000 population)\n<br/>,'Polio'-Polio (Pol3) immunization coverage among 1-year-olds (out of 100%)\n<br/>,'Total expenditure'-General government expenditure on health as a percentage of total government expenditure (out of 100%)\n<br/>,'Diphtheria '-DTP3 immunization coverage among 1-year-olds (out of 100%)\n<br/>,' HIV/AIDS'-Deaths per 1000 live births (0-4 years) due to HIV (out of per 1000 population)\n<br/>,'GDP'-Gross Domestic Product per capita (in USD)\n<br/>,'Population'-Population of the country\n<br/>,' thinness  1-19 years'-Prevalence of thinness among children and adolescents for Age 10 to 19 (out of 100%)\n<br/>,' thinness 5-9 years'-Prevalence of thinness among children for Age 5 to 9 (out of 100%)\n<br/>,'Income composition of resources'-Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n<br/>,'Schooling'-Number of years of Schooling (years)\n<br/>\n<br/>\n<br/>**STEPS IN MODELLING**\n<br/>1.Data Acquisation\n<br/>2.Data understanding\n<br/>3.Data visualisation/EDA\n<br/>4.Data cleaning/missing imputation/typecasting\n<br/>5.Sampling/ bias removal\n<br/>6.Anomaly detection\n<br/>7.Feature selection/importance\n<br/>8.Azure ML Model trigger\n<br/>9.Model Interpretation\n<br/>10.Telemetry\n<br/>\n<br/>\n<br/>**LOGICAL SCALING OF COLS**\n<br/>col1=column/TotalPopulation *1000---> Out of 1000 people data\n<br/>col2=column/TotalPopulation *100---> Out of 100 people data or % data\n<br/>Bring everything to same scale. i.e Percentage data so div col1/10\n<br/>We should not bring data at scale as Absolute count out of total population because the total population is different for different countries so the comparison would not be fair.\n<br/>\n<br/>**FEATURE ENGINEERING**\n<br/>Summation of features in % eg: Immunization='Hepatitis B'+ 'Polio'+ 'Diphtheria'\n<br/>X%           Y%          Z%          ---% of tot populations\n<br/>x/T*100      y/T*100     y/T*100     ---x,y,z is the number of people out of T total population\n<br/>avg no. of people of total categories=(x+y+z)/3\n<br/>% of avg no. of people               =((x+y+z)/3)/T *100\n<br/>                                     =1/3 * ((x+y+z)/100)\n<br/>                                     =1/3 * ((x/T + y/T + z/T)*100)\n<br/>                                     =1/3 * (X% +Y% +Z%)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Problem Definition","showTitle":true,"inputWidgets":{},"nuid":"73b597be-ae22-414b-a19e-d46b1223e66c"}}},{"cell_type":"markdown","source":["## Import functions from Master Notebook:\nImport the Functions and dependencies from the Master notebook to be used in the Trigger Notebook"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64aff489-c3bf-4c96-aef0-d071291e3f79"}}},{"cell_type":"code","source":["%run .../.../AMLMasterNotebook"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Import Functions","showTitle":false,"inputWidgets":{},"nuid":"01b686e9-c129-422b-bd1a-ac0a6af69a8d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 1.Data Acquisition\n1.Acquisition of data from datasource ADLS path in CSV/Parquet/JSON etc format.\n<br/>2.Logical Transformations in data- For the WHO data we get features in mixed scales of Percentage out of Total Population & out of 1000 people, so we make everything to a scale of out of 100% scale for uniformity in data features values. \n<br/>3.Transforming columns into required datatypes, converting to pandas df, persisiting actual dataset, intoducing a column 'Index' to assign a unique identifier to each dataset row so that this canm be used to retrieve back the original form after any data manupulations."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7b63622-8e5d-4316-b9a7-b71197faff7a"}}},{"cell_type":"code","source":["%scala\n//<USER INPUT FILEPATH PARQUET OR CSV>\n\nval filepath= \"adl://<Your ADLS Name>.azuredatalakestore.net/.../WHO.csv\"\nvar df=spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").load(filepath)\n//val filepath =\"abfss:/.../.parquet\"\n//var df = spark.read.parquet(filepath)\ndf.createOrReplaceTempView(\"vw\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Read Data from Lake","showTitle":true,"inputWidgets":{},"nuid":"b706b583-deb8-4bab-8777-27b1ead82536"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df= spark.sql(\"\"\"With Original as\n(select \n`Country` AS  Country\n,`Year` AS  Year\n,`Status` AS  Status\n,`Life expectancy ` AS  LifeExpectancy\n,`Adult Mortality` AS  AdultMortality\n,`infant deaths` AS  InfantDeaths\n,`Alcohol` AS  Alcohol\n,`percentage expenditure` AS  PercentageExpenditure\n,`Hepatitis B` AS  HepatitisB\n,`Measles ` AS  Measles\n,` BMI ` AS  Bmi\n,`under-five deaths ` AS  UnderFiveDeaths\n,`Polio` AS  Polio\n,`Total expenditure` AS  TotalExpenditure\n,`Diphtheria ` AS  Diphtheria\n,` HIV/AIDS` AS  HivAids\n,`GDP` AS  Gdp\n,`Population` AS  Population\n,` thinness  1-19 years` AS  Thinness1_19Years\n,` thinness 5-9 years` AS  Thinness5_9Years\n,`Income composition of resources` AS  IncomeCompositionOfResources\n,`Schooling` AS  Schooling\nFrom vw\n)\nSelect \nCountry\n,Year\n,Status\n,LifeExpectancy\n,ROUND(AdultMortality/10,2) AS AdultMortality\n,ROUND(InfantDeaths/10,2) AS InfantDeaths\n,Alcohol\n,PercentageExpenditure\n,HepatitisB\n,ROUND(Measles/10,2) AS Measles\n,Bmi\n,ROUND(UnderFiveDeaths/10,2) AS UnderFiveDeaths\n,Polio\n,TotalExpenditure\n,Diphtheria\n,ROUND(HivAids/10,2) AS HivAids\n,Gdp\n,Population\n,Thinness1_19Years\n,Thinness5_9Years\n,IncomeCompositionOfResources\n,Schooling\n,ROUND((HepatitisB + Polio + Diphtheria)/3,2) AS Immunization_perc\n,ROUND((InfantDeaths/10 + UnderFiveDeaths/10 + HivAids/10 + AdultMortality/10)/3,2) AS Mortality_perc\n,ROUND((PercentageExpenditure + TotalExpenditure)/3,2) AS EconomicInvestment_perc\nFROM Original\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Logical transformation of data","showTitle":true,"inputWidgets":{},"nuid":"cd6fed42-d6fd-4481-9db6-143417f30aaa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom pyspark.sql.functions import col\n# <USER INPUT COLUMN NAMES WITH DATAYPES IN RESPECTIVE BUCKET>\n\nAll_Cols=['Country'\n,'Year'\n,'Status'\n,'LifeExpectancy'\n,'AdultMortality'\n,'InfantDeaths'\n,'Alcohol'\n,'PercentageExpenditure'\n,'HepatitisB'\n,'Measles'\n,'Bmi'\n,'UnderFiveDeaths'\n,'Polio'\n,'TotalExpenditure'\n,'Diphtheria'\n,'HivAids'\n,'Gdp'\n,'Population'\n,'Thinness1_19Years'\n,'Thinness5_9Years'\n,'IncomeCompositionOfResources'\n,'Schooling'\n,'Immunization_perc'\n,'Mortality_perc'\n,'EconomicInvestment_perc'\n]\ncols_string=['Country'\n,'Year'\n,'Status'\n]\ncols_int=[]\ncols_bool=[]\ncols_Float=['LifeExpectancy'\n,'AdultMortality'\n,'InfantDeaths'\n,'Alcohol'\n,'PercentageExpenditure'\n,'HepatitisB'\n,'Measles'\n,'Bmi'\n,'UnderFiveDeaths'\n,'Polio'\n,'TotalExpenditure'\n,'Diphtheria'\n,'HivAids'\n,'Gdp'\n,'Population'\n,'Thinness1_19Years'\n,'Thinness5_9Years'\n,'IncomeCompositionOfResources'\n,'Schooling'\n,'Immunization_perc'\n,'Mortality_perc'\n,'EconomicInvestment_perc'\n ]\n\nfor col_name in cols_int:\n    df = df.withColumn(col_name, col(col_name).cast('Int'))  \nfor col_name in cols_Float:\n    df = df.withColumn(col_name, col(col_name).cast('float')) \nfor col_name in cols_bool:\n    df = df.withColumn(col_name, col(col_name).cast('bool')) \n    \n\n#Convert Spark df to pandas\ninput_dataframe = df.toPandas()\n\n#Add a unique identifier to each row\ninput_dataframe['Index'] = np.arange(len(input_dataframe))\n\n\n# Column names: remove white spaces and convert to Camel case\n#input_dataframe.columns= input_dataframe.columns.str.strip().str.title().str.replace(' ', '')\n#print(input_dataframe.columns)\n\noutdir = '/dbfs/FileStore/who.csv'\ninput_dataframe.to_csv(outdir, index=False)\n#input_dataframe = pd.read_csv(\"/dbfs/FileStore/Dataframe.csv\", header='infer')\ninput_dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data columns and structural transformation","showTitle":true,"inputWidgets":{},"nuid":"96552a0b-6af9-42f9-bdfe-8accec92b64a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 2.Data Exploration\n1.Exploratory Data Analysis (EDA)- To understand the overall data at hand, analysing each feature independently for its' statistics, the correlation and interraction between variables, data sample etc. \n<br/>2.Data Profiling Plots- To analyse the Categorical and Numerical columns separately for any trend in data, biasness in data etc."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d4a17ac-229d-40a6-ab11-36c85e45ab22"}}},{"cell_type":"code","source":["import pandas as pd\ninput_dataframe = pd.read_csv(\"/dbfs/FileStore/who.csv\", header='infer')\n\nData_Profiling_viaPandasProfiling(input_dataframe,'WHO','EDA')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"EDA","showTitle":true,"inputWidgets":{},"nuid":"f53c7125-bb51-4d65-a61d-e22a9424e433"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["input_dataframe = pd.read_csv(\"/dbfs/FileStore/who.csv\", header='infer')\n\n#User Inputs\nCategorical_cols=['Country'\n,'Year'\n,'Status']\nNumeric_cols=['LifeExpectancy'\n,'AdultMortality'\n,'InfantDeaths'\n,'Alcohol'\n,'PercentageExpenditure'\n,'HepatitisB'\n,'Measles'\n,'Bmi'\n,'UnderFiveDeaths'\n,'Polio'\n,'TotalExpenditure'\n,'Diphtheria'\n,'HivAids'\n,'Gdp'\n,'Population'\n,'Thinness1_19Years'\n,'Thinness5_9Years'\n,'IncomeCompositionOfResources'\n,'Schooling'\n,'Immunization_perc'\n,'Mortality_perc'\n,'EconomicInvestment_perc'\n]\nLabel_col='LifeExpectancy'\n\n#Data_Profiling_Plots(input_dataframe,Categorical_cols,Numeric_cols,Label_col)\nData_Profiling_Plots(input_dataframe,Categorical_cols,Numeric_cols,Label_col)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Profiling Plots","showTitle":true,"inputWidgets":{},"nuid":"34761f5f-b7a6-405f-b43c-e69053cb9f21"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 3.Cleansing\nTo clean the data from NULL values, fix structural errors in columns, drop empty columns, encode the categorical values, normalise the data to bring to the same scale. We also check the Data Distribution via Correlation heatmap of original input dataset v/s the Cleansed dataset to validate whether or not the transformations hampered the original data trend/density."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cebbad80-b6b1-4f4c-96d9-c82bb9a67536"}}},{"cell_type":"code","source":["df = pd.read_csv(\"/dbfs/FileStore/who.csv\", header='infer')\n#df=df.drop(['Index'], axis = 1) # Index is highest variability column hence always imp along PC but has no business value. You can append columns to be dropped by your choice here in the list\n\n#autodatacleaner(inputdf,filepath,input_appname,task_type)\ninputdf_new=autodatacleaner(df,\"/dbfs/FileStore/who.csv\",\"WHO\",\"Data Cleanser\")\nprint(\"Total rows in the new pandas dataframe:\",len(inputdf_new.index))\n\n#persist cleansed data sets \nfilepath1 = '/dbfs/FileStore/Cleansed_WHO.csv'\ninputdf_new.to_csv(filepath1, index=False)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62c8f6be-ea54-4a25-9721-0a9d0d84408e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Cleansed=pd.read_csv(\"/dbfs/FileStore/who.csv\", header='infer')\n\ndisplay(Data_Profiling_Fin(Cleansed))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Distribution (Heatmap)- Input dataset","showTitle":true,"inputWidgets":{},"nuid":"96972caa-5aef-4ee0-ad30-d9016d42e621"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["Cleansed=pd.read_csv(\"/dbfs/FileStore/Cleansed_WHO.csv\", header='infer')\n\ndisplay(Data_Profiling_Fin(Cleansed))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Distribution (Heatmap)- Cleansed dataset","showTitle":true,"inputWidgets":{},"nuid":"05164805-5421-4399-a36f-a78d7525dd58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 4.Sampling\nPerform Stratified, Systematic, Random, Cluster sampling over data and compare the so obtained sampled dataset with the original data using a NULL Hypothesis, and suggest the best sample obtained thus. Compare the data densities of sampled datasets with that of the original input dataset to validate that our sample matches the data trend of original set."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94320491-ab1c-42cb-ac45-4fe2689caa74"}}},{"cell_type":"code","source":["input_dataframe = pd.read_csv(\"/dbfs/FileStore/Cleansed_WHO.csv\", header='infer')\nsubsample_final = pd.DataFrame()\nsubsample1 = pd.DataFrame()\nsubsample2 = pd.DataFrame()\nsubsample3 = pd.DataFrame()\nsubsample4 = pd.DataFrame()\n\n#Sampling(input_dataframe,filepath,task_type,input_appname,cluster_classified_col_ifany(Supervised))\nsubsample_final,subsample1,subsample2,subsample3,subsample4=Sampling(input_dataframe,\"/dbfs/FileStore/Cleansed_WHO.csv\",'Sampling','WHO','Status')\n\n\n#persist sampled data sets \nfilepath1 = '/dbfs/FileStore/StratifiedSampled_who.csv'\nsubsample1.to_csv(filepath1, index=False)\nfilepath2 = '/dbfs/FileStore/RandomSampled_who.csv'\nsubsample2.to_csv(filepath2, index=False)\nfilepath3 = '/dbfs/FileStore/SystematicSampled_who.csv'\nsubsample3.to_csv(filepath3, index=False)\nfilepath4 = '/dbfs/FileStore/ClusterSampled_who.csv' #The oversampled data without sampling is in '/dbfs/FileStore/SMOTE.csv'\nsubsample4.to_csv(filepath4, index=False)\nfilepath = '/dbfs/FileStore/subsample_final_who.csv'\nsubsample_final.to_csv(filepath, index=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b1d352c-e01a-456f-82fe-3efe9b51da77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["input_dataframe = pd.read_csv(\"/dbfs/FileStore/who.csv\", header='infer')\n\ndisplay(display_DataDistribution(input_dataframe,'LifeExpectancy'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Distribution (Histogram)- Input dataset","showTitle":true,"inputWidgets":{},"nuid":"df43a70e-78aa-405b-af9c-e5f6c93f6a4c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["subsample1 = pd.read_csv(\"/dbfs/FileStore/StratifiedSampled_who.csv\", header='infer')\n\ndisplay(display_DataDistribution(subsample1,'LifeExpectancy'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Distribution (Histogram)- Stratified Sampled dataset","showTitle":true,"inputWidgets":{},"nuid":"8bc0d99e-9afe-4baa-8f24-ff7a008b416d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["subsample2 = pd.read_csv(\"/dbfs/FileStore/RandomSampled_who.csv\", header='infer')\n\ndisplay(display_DataDistribution(subsample2,'LifeExpectancy'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Distribution (Histogram)- Random Sampled dataset","showTitle":true,"inputWidgets":{},"nuid":"1b8865f1-54ce-4884-95be-d042bdf304d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["subsample3 = pd.read_csv(\"/dbfs/FileStore/SystematicSampled_who.csv\", header='infer')\n\ndisplay(display_DataDistribution(subsample3,'LifeExpectancy'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Distribution (Histogram)- Systematic Sampled dataset","showTitle":true,"inputWidgets":{},"nuid":"f78cd2a3-564c-42bc-8ee5-14230889bc3a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["subsample4 = pd.read_csv(\"/dbfs/FileStore/ClusterSampled_who.csv\", header='infer')\n\ndisplay(display_DataDistribution(subsample4,'LifeExpectancy'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Data Distribution (Histogram)- Clustered Sampled dataset","showTitle":true,"inputWidgets":{},"nuid":"275ba655-9017-4221-9642-7c3541518be6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 5.Anomaly Detection\nIterate data over various Anomaly-detection techniques and estimate the number of Inliers and Outliers for each."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9f606c5-ee89-4ed1-9dff-1f3e95c37c33"}}},{"cell_type":"code","source":["#Calling the Anamoly Detection Function for identifying outliers \noutliers_fraction = 0.05\ndf =pd.read_csv(\"/dbfs/FileStore/ClusterSampled_who.csv\", header='infer')\ntarget_variable = 'LifeExpectancy'\nvariables_to_analyze='Population'\n\nAnomalyDetection(df,target_variable,variables_to_analyze,outliers_fraction,'anomaly_test','WHO')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93afcdce-1c38-4cbc-8560-21d2fb695e38"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 6.Feature Selection\nPerform feature selection on the basis of Feature Importance ranking, correlation values, variance within the column.\nChoose features with High Importance value score, drop one of the two highly correlated features, drop features which offer zero variability to data and thus do not increase the entropy of dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"583407e7-18f9-42eb-827c-d3fffcb5cc60"}}},{"cell_type":"code","source":["df =pd.read_csv(\"/dbfs/FileStore/ClusterSampled_who.csv\", header='infer')\nFeatureSelection(df,'LifeExpectancy','Continuous',\"/dbfs/FileStore/ClusterSampled_who.csv\",'WHO','FeatureSelection')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8422d7c6-aada-41ea-8742-54cdd09514d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 6.Auto ML Trigger - after preprocessing\nTrigger Azure auto ML, pick the best model so obtained and use it to predict the label column. Calculate the Weighted Absolute Accuracy amd push to telemetry. also obtain the data back in original format by using the unique identifier of each row 'Index' and report Actual v/s Predicted Columns. We also provide the direct link to the azure Portal Run for the current experiment for users to follow."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4a27061-a756-4376-bad5-2e0ac987681e"}}},{"cell_type":"code","source":["import pandas as pd\ndfclean = pd.read_csv(\"/dbfs/FileStore/ClusterSampled_who.csv\", header='infer')\n\n#Drop Feature selection recommended features Unimportant/Highly Correlated\ndfclean.drop(['UnderFiveDeaths', 'Thinness5_9Years', 'EconomicInvestment_perc'], axis=1, inplace=True) \n\n#AutoMLFunc(subscription_id,resource_group,workspace_name,input_dataframe,label_col,task_type,input_appname)\ndf=AutoMLFunc(<subscription_id>,<resource_group>,<workspace_name>,dfclean,'LifeExpectancy','regression','WHO')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Azure Auto ML Trigger","showTitle":true,"inputWidgets":{},"nuid":"7cb25d83-c2f9-4324-b153-9ccbbeccf86e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["##df has just index,y actual, y predicted cols, as rest all cols are encoded after manipulation\nfor col in df.columns:\n  if col not in [\"y_predict\",\"y_actual\",\"Index\"]: \n    df.drop([col], axis=1, inplace=True)\n    \n#dataframe is the actual input dataset     \ndataframe = pd.read_csv(\"/dbfs/FileStore/who.csv\", header='infer')\n\n#Merging Actual Input dataframe with AML output df using Index column\ndataframe_fin = pd.merge(left=dataframe, right=df, left_on='Index', right_on='Index')\n\n#De-coding the label columns using scaling with actual label input\ndataframe_fin['LifeExpectancy_Actual'] = dataframe_fin['LifeExpectancy']\ndataframe_fin['LifeExpectancy_Predicted'] = (dataframe_fin['LifeExpectancy'] / dataframe_fin.y_actual)* dataframe_fin.y_predict\n\n#div by zero in error above eqn raises Nans so replace all Nans with 0\ndataframe_fin['LifeExpectancy_Predicted'].fillna(0, inplace=True)\n\n# deleting unwanted intermediate columns \nfor col in dataframe_fin.columns:\n  if col in [\"y_predict\",\"y_actual\"]: \n    dataframe_fin.drop([col], axis=1, inplace=True)\n    \ndataframe_fin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Obtain back data in original format after modelling","showTitle":true,"inputWidgets":{},"nuid":"a827a009-48d9-444b-b0f3-a63081eaca04"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 7.Model Interpretation, Feature Importance\nWe can explore the model by splitting the Model metrics over various cohorts and analyse the data and model performance for each subclass.We can also get Global & Local feature Importance values for the Model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c08dd9e9-a3fc-41bd-9e4b-81c6092f35cb"}}},{"cell_type":"code","source":["#featureset should match with what was passed as X as part of the model training experiment\ndf= pd.read_csv(\"/dbfs/FileStore/ClusterSampled_who.csv\", header='infer')\n\nModelInterpret(df,'LifeExpectancy',<subscription_id>,<resource_group>,<workspace_name>,<run_id>,<iteration>,'regression')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beaf4701-2638-4349-a5b0-2ee234d9119d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 8.Telemetry\nWe can get comparative analysis of experiments via the telemetry captured for each and every step of the model run."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b06bd82f-d1c8-40fb-ac81-5e180334d527"}}},{"cell_type":"code","source":["%sql \nselect * from  TelemetryTable\nwhere MLKey='WHO' and Step='regression' \norder by TimeGenerated desc \n\n--Experimentation Accuracies:\n--1.Cleansing but no oversampling by 'Status' col by SMOTE=96%\n--2.Cleansing+SMOTE+Logical scaling of Percentage and OutOfThousand columns=97.2%\n--3.Cleansing+SMOTE+Logical scaling of Percentage and OutOfThousand columns+FeatureEngg=97.19% (accuracy dropped as we noticed high correlation variable (refer feature selection) EconomicInvestment_perc added as per feature engineered)\n--4.Cleansing+SMOTE+Logical scaling of Percentage and OutOfThousand columns+FeatureEngg+FeatureSelection=97.17%\n--5.Cleansing+SMOTE+Logical scaling of Percentage and OutOfThousand columns+FeatureEngg+FeatureSelection+AnomaliesHandling="],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"158e50aa-17b1-4174-a408-ab9dd023e088"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Trigger_Final(WHO Life Expectancy Pred) (git)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4321189738449277}},"nbformat":4,"nbformat_minor":0}
