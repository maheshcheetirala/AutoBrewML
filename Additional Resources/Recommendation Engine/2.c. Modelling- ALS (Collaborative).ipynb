{"cells":[{"cell_type":"markdown","source":["## ALGO DEEP DIVE:\nAlternating Least Square is a matrix factorisation algorithm implemented in Apache Spark ML and built for large-scale collaborative filtering problems."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b613a5ea-a8d8-4b15-85c0-7ca5eb901048"}}},{"cell_type":"code","source":["%pip install recommenders\n%pip install datetime"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9318270a-f427-41d8-b199-f575aa123819"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting recommenders\n  Using cached recommenders-1.1.0-py3-none-manylinux1_x86_64.whl (335 kB)\nCollecting memory-profiler&lt;1,&gt;=0.54.0\n  Using cached memory_profiler-0.60.0-py3-none-any.whl\nCollecting cornac&lt;2,&gt;=1.1.2\n  Using cached cornac-1.14.2-cp38-cp38-manylinux1_x86_64.whl (14.4 MB)\nRequirement already satisfied: transformers&lt;5,&gt;=2.5.0 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (4.15.0)\nRequirement already satisfied: tqdm&lt;5,&gt;=4.31.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (4.59.0)\nRequirement already satisfied: seaborn&lt;1,&gt;=0.8.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (0.11.1)\nRequirement already satisfied: jinja2&lt;3.1,&gt;=2 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (2.11.2)\nCollecting category-encoders&lt;2,&gt;=1.3.0\n  Using cached category_encoders-1.3.0-py2.py3-none-any.whl (61 kB)\nRequirement already satisfied: pyyaml&lt;6,&gt;=5.4.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (5.4.1)\nRequirement already satisfied: pandas&lt;2,&gt;1.0.3 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (1.1.5)\nCollecting bottleneck&lt;2,&gt;=1.2.1\n  Using cached Bottleneck-1.3.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_24_x86_64.whl (331 kB)\nRequirement already satisfied: requests&lt;3,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (2.25.1)\nRequirement already satisfied: matplotlib&lt;4,&gt;=2.2.2 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (3.4.2)\nRequirement already satisfied: nltk&lt;4,&gt;=3.4 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (3.6.1)\nRequirement already satisfied: scipy&lt;2,&gt;=1.0.0 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (1.5.2)\nCollecting scikit-surprise&gt;=1.0.6\n  Using cached scikit_surprise-1.1.1-cp38-cp38-linux_x86_64.whl\nRequirement already satisfied: lightgbm&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (3.2.1)\nCollecting retrying&gt;=1.3.3\n  Using cached retrying-1.3.3-py3-none-any.whl\nRequirement already satisfied: numba&lt;1,&gt;=0.38.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (0.53.1)\nCollecting lightfm&lt;2,&gt;=1.15\n  Using cached lightfm-1.16-cp38-cp38-linux_x86_64.whl\nCollecting pandera[strategies]&gt;=0.6.5\n  Using cached pandera-0.10.1-py3-none-any.whl (197 kB)\nRequirement already satisfied: numpy&gt;=1.19 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (1.19.5)\nRequirement already satisfied: scikit-learn&lt;1.0.3,&gt;=0.22.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (0.22.2.post1)\nRequirement already satisfied: statsmodels&gt;=0.6.1 in /databricks/python3/lib/python3.8/site-packages (from category-encoders&lt;2,&gt;=1.3.0-&gt;recommenders) (0.11.1)\nRequirement already satisfied: patsy&gt;=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from category-encoders&lt;2,&gt;=1.3.0-&gt;recommenders) (0.5.1)\nCollecting powerlaw\n  Using cached powerlaw-1.5-py3-none-any.whl (24 kB)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2&lt;3.1,&gt;=2-&gt;recommenders) (2.0.1)\nRequirement already satisfied: wheel in /databricks/python3/lib/python3.8/site-packages (from lightgbm&gt;=2.2.1-&gt;recommenders) (0.36.2)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (0.10.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (8.2.0)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (2.4.7)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (2.8.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from cycler&gt;=0.10-&gt;matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (1.15.0)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.8/site-packages (from memory-profiler&lt;1,&gt;=0.54.0-&gt;recommenders) (5.8.0)\nRequirement already satisfied: regex in /databricks/python3/lib/python3.8/site-packages (from nltk&lt;4,&gt;=3.4-&gt;recommenders) (2021.4.4)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk&lt;4,&gt;=3.4-&gt;recommenders) (7.1.2)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk&lt;4,&gt;=3.4-&gt;recommenders) (0.14.1)\nRequirement already satisfied: llvmlite&lt;0.37,&gt;=0.36.0rc1 in /databricks/python3/lib/python3.8/site-packages (from numba&lt;1,&gt;=0.38.1-&gt;recommenders) (0.36.0)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.8/site-packages (from numba&lt;1,&gt;=0.38.1-&gt;recommenders) (49.6.0)\nRequirement already satisfied: pytz&gt;=2017.2 in /databricks/python3/lib/python3.8/site-packages (from pandas&lt;2,&gt;1.0.3-&gt;recommenders) (2020.5)\nCollecting typing-inspect&gt;=0.6.0\n  Using cached typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (1.12.1)\nCollecting pandas&lt;2,&gt;1.0.3\n  Using cached pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\nRequirement already satisfied: pyarrow in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (3.0.0)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (21.3)\nRequirement already satisfied: pydantic in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (1.8.2)\nCollecting hypothesis&gt;=5.41.1\n  Using cached hypothesis-6.41.0-py3-none-any.whl (380 kB)\nRequirement already satisfied: sortedcontainers&lt;3.0.0,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from hypothesis&gt;=5.41.1-&gt;pandera[strategies]&gt;=0.6.5-&gt;recommenders) (2.4.0)\nRequirement already satisfied: attrs&gt;=19.2.0 in /databricks/python3/lib/python3.8/site-packages (from hypothesis&gt;=5.41.1-&gt;pandera[strategies]&gt;=0.6.5-&gt;recommenders) (20.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (2.10)\nRequirement already satisfied: sacremoses in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (0.0.46)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (3.0.12)\nRequirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (0.10.3)\nRequirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.1.0 in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (0.1.2)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /databricks/python3/lib/python3.8/site-packages (from huggingface-hub&lt;1.0,&gt;=0.1.0-&gt;transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (4.1.1)\nCollecting mypy-extensions&gt;=0.3.0\n  Using cached mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\nCollecting mpmath\n  Using cached mpmath-1.2.1-py3-none-any.whl (532 kB)\nInstalling collected packages: mypy-extensions, typing-inspect, pandas, mpmath, powerlaw, pandera, hypothesis, scikit-surprise, retrying, memory-profiler, lightfm, cornac, category-encoders, bottleneck, recommenders\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.1.5\n    Not uninstalling pandas at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b5f13af0-4ffb-476f-81cb-7da613fdff26\n    Can&#39;t uninstall &#39;pandas&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-profiling 3.1.0 requires joblib~=1.0.1, but you have joblib 0.14.1 which is incompatible.\nazureml-training-tabular 1.40.0 requires pandas==1.1.5, but you have pandas 1.4.2 which is incompatible.\nazureml-train-automl-runtime 1.40.0.post1 requires pandas==1.1.5, but you have pandas 1.4.2 which is incompatible.\nazureml-automl-runtime 1.40.0 requires pandas==1.1.5, but you have pandas 1.4.2 which is incompatible.\nSuccessfully installed bottleneck-1.3.4 category-encoders-1.3.0 cornac-1.14.2 hypothesis-6.41.0 lightfm-1.16 memory-profiler-0.60.0 mpmath-1.2.1 mypy-extensions-0.4.3 pandas-1.4.2 pandera-0.10.1 powerlaw-1.5 recommenders-1.1.0 retrying-1.3.3 scikit-surprise-1.1.1 typing-inspect-0.7.1\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting datetime\n  Using cached DateTime-4.4-py2.py3-none-any.whl (51 kB)\nCollecting zope.interface\n  Using cached zope.interface-5.4.0-cp38-cp38-manylinux2010_x86_64.whl (259 kB)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (from datetime) (2020.5)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.8/site-packages (from zope.interface-&gt;datetime) (49.6.0)\nInstalling collected packages: zope.interface, datetime\nSuccessfully installed datetime-4.4 zope.interface-5.4.0\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting recommenders\n  Using cached recommenders-1.1.0-py3-none-manylinux1_x86_64.whl (335 kB)\nCollecting memory-profiler&lt;1,&gt;=0.54.0\n  Using cached memory_profiler-0.60.0-py3-none-any.whl\nCollecting cornac&lt;2,&gt;=1.1.2\n  Using cached cornac-1.14.2-cp38-cp38-manylinux1_x86_64.whl (14.4 MB)\nRequirement already satisfied: transformers&lt;5,&gt;=2.5.0 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (4.15.0)\nRequirement already satisfied: tqdm&lt;5,&gt;=4.31.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (4.59.0)\nRequirement already satisfied: seaborn&lt;1,&gt;=0.8.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (0.11.1)\nRequirement already satisfied: jinja2&lt;3.1,&gt;=2 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (2.11.2)\nCollecting category-encoders&lt;2,&gt;=1.3.0\n  Using cached category_encoders-1.3.0-py2.py3-none-any.whl (61 kB)\nRequirement already satisfied: pyyaml&lt;6,&gt;=5.4.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (5.4.1)\nRequirement already satisfied: pandas&lt;2,&gt;1.0.3 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (1.1.5)\nCollecting bottleneck&lt;2,&gt;=1.2.1\n  Using cached Bottleneck-1.3.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_24_x86_64.whl (331 kB)\nRequirement already satisfied: requests&lt;3,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (2.25.1)\nRequirement already satisfied: matplotlib&lt;4,&gt;=2.2.2 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (3.4.2)\nRequirement already satisfied: nltk&lt;4,&gt;=3.4 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (3.6.1)\nRequirement already satisfied: scipy&lt;2,&gt;=1.0.0 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (1.5.2)\nCollecting scikit-surprise&gt;=1.0.6\n  Using cached scikit_surprise-1.1.1-cp38-cp38-linux_x86_64.whl\nRequirement already satisfied: lightgbm&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (3.2.1)\nCollecting retrying&gt;=1.3.3\n  Using cached retrying-1.3.3-py3-none-any.whl\nRequirement already satisfied: numba&lt;1,&gt;=0.38.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (0.53.1)\nCollecting lightfm&lt;2,&gt;=1.15\n  Using cached lightfm-1.16-cp38-cp38-linux_x86_64.whl\nCollecting pandera[strategies]&gt;=0.6.5\n  Using cached pandera-0.10.1-py3-none-any.whl (197 kB)\nRequirement already satisfied: numpy&gt;=1.19 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (1.19.5)\nRequirement already satisfied: scikit-learn&lt;1.0.3,&gt;=0.22.1 in /databricks/python3/lib/python3.8/site-packages (from recommenders) (0.22.2.post1)\nRequirement already satisfied: statsmodels&gt;=0.6.1 in /databricks/python3/lib/python3.8/site-packages (from category-encoders&lt;2,&gt;=1.3.0-&gt;recommenders) (0.11.1)\nRequirement already satisfied: patsy&gt;=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from category-encoders&lt;2,&gt;=1.3.0-&gt;recommenders) (0.5.1)\nCollecting powerlaw\n  Using cached powerlaw-1.5-py3-none-any.whl (24 kB)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2&lt;3.1,&gt;=2-&gt;recommenders) (2.0.1)\nRequirement already satisfied: wheel in /databricks/python3/lib/python3.8/site-packages (from lightgbm&gt;=2.2.1-&gt;recommenders) (0.36.2)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (0.10.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (8.2.0)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (2.4.7)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (2.8.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from cycler&gt;=0.10-&gt;matplotlib&lt;4,&gt;=2.2.2-&gt;recommenders) (1.15.0)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.8/site-packages (from memory-profiler&lt;1,&gt;=0.54.0-&gt;recommenders) (5.8.0)\nRequirement already satisfied: regex in /databricks/python3/lib/python3.8/site-packages (from nltk&lt;4,&gt;=3.4-&gt;recommenders) (2021.4.4)\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk&lt;4,&gt;=3.4-&gt;recommenders) (7.1.2)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk&lt;4,&gt;=3.4-&gt;recommenders) (0.14.1)\nRequirement already satisfied: llvmlite&lt;0.37,&gt;=0.36.0rc1 in /databricks/python3/lib/python3.8/site-packages (from numba&lt;1,&gt;=0.38.1-&gt;recommenders) (0.36.0)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.8/site-packages (from numba&lt;1,&gt;=0.38.1-&gt;recommenders) (49.6.0)\nRequirement already satisfied: pytz&gt;=2017.2 in /databricks/python3/lib/python3.8/site-packages (from pandas&lt;2,&gt;1.0.3-&gt;recommenders) (2020.5)\nCollecting typing-inspect&gt;=0.6.0\n  Using cached typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\nRequirement already satisfied: wrapt in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (1.12.1)\nCollecting pandas&lt;2,&gt;1.0.3\n  Using cached pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\nRequirement already satisfied: pyarrow in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (3.0.0)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (21.3)\nRequirement already satisfied: pydantic in /databricks/python3/lib/python3.8/site-packages (from pandera[strategies]&gt;=0.6.5-&gt;recommenders) (1.8.2)\nCollecting hypothesis&gt;=5.41.1\n  Using cached hypothesis-6.41.0-py3-none-any.whl (380 kB)\nRequirement already satisfied: sortedcontainers&lt;3.0.0,&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from hypothesis&gt;=5.41.1-&gt;pandera[strategies]&gt;=0.6.5-&gt;recommenders) (2.4.0)\nRequirement already satisfied: attrs&gt;=19.2.0 in /databricks/python3/lib/python3.8/site-packages (from hypothesis&gt;=5.41.1-&gt;pandera[strategies]&gt;=0.6.5-&gt;recommenders) (20.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;recommenders) (2.10)\nRequirement already satisfied: sacremoses in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (0.0.46)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (3.0.12)\nRequirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (0.10.3)\nRequirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.1.0 in /databricks/python3/lib/python3.8/site-packages (from transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (0.1.2)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /databricks/python3/lib/python3.8/site-packages (from huggingface-hub&lt;1.0,&gt;=0.1.0-&gt;transformers&lt;5,&gt;=2.5.0-&gt;recommenders) (4.1.1)\nCollecting mypy-extensions&gt;=0.3.0\n  Using cached mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\nCollecting mpmath\n  Using cached mpmath-1.2.1-py3-none-any.whl (532 kB)\nInstalling collected packages: mypy-extensions, typing-inspect, pandas, mpmath, powerlaw, pandera, hypothesis, scikit-surprise, retrying, memory-profiler, lightfm, cornac, category-encoders, bottleneck, recommenders\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.1.5\n    Not uninstalling pandas at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b5f13af0-4ffb-476f-81cb-7da613fdff26\n    Can&#39;t uninstall &#39;pandas&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-profiling 3.1.0 requires joblib~=1.0.1, but you have joblib 0.14.1 which is incompatible.\nazureml-training-tabular 1.40.0 requires pandas==1.1.5, but you have pandas 1.4.2 which is incompatible.\nazureml-train-automl-runtime 1.40.0.post1 requires pandas==1.1.5, but you have pandas 1.4.2 which is incompatible.\nazureml-automl-runtime 1.40.0 requires pandas==1.1.5, but you have pandas 1.4.2 which is incompatible.\nSuccessfully installed bottleneck-1.3.4 category-encoders-1.3.0 cornac-1.14.2 hypothesis-6.41.0 lightfm-1.16 memory-profiler-0.60.0 mpmath-1.2.1 mypy-extensions-0.4.3 pandas-1.4.2 pandera-0.10.1 powerlaw-1.5 recommenders-1.1.0 retrying-1.3.3 scikit-surprise-1.1.1 typing-inspect-0.7.1\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting datetime\n  Using cached DateTime-4.4-py2.py3-none-any.whl (51 kB)\nCollecting zope.interface\n  Using cached zope.interface-5.4.0-cp38-cp38-manylinux2010_x86_64.whl (259 kB)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (from datetime) (2020.5)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.8/site-packages (from zope.interface-&gt;datetime) (49.6.0)\nInstalling collected packages: zope.interface, datetime\nSuccessfully installed datetime-4.4 zope.interface-5.4.0\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# set the environment path to find Recommenders\nimport sys\nimport pyspark\nfrom pyspark.ml.recommendation import ALS\nimport pyspark.sql.functions as F\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField\nfrom pyspark.sql.types import StringType, FloatType, IntegerType, LongType\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom recommenders.utils.timer import Timer\nfrom recommenders.datasets import movielens\nfrom recommenders.utils.notebook_utils import is_jupyter\nfrom recommenders.datasets.spark_splitters import spark_random_split\nfrom recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\nfrom recommenders.utils.spark_utils import start_or_get_spark\n\nprint(\"System version: {}\".format(sys.version))\nprint(\"Spark version: {}\".format(pyspark.__version__))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e522d98-39f5-432f-9075-3d6cc2037393"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">System version: 3.8.10 (default, Nov 26 2021, 20:14:08) \n[GCC 9.3.0]\nSpark version: 3.2.1\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">System version: 3.8.10 (default, Nov 26 2021, 20:14:08) \n[GCC 9.3.0]\nSpark version: 3.2.1\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df = spark.read.format(\"csv\").options(header='true', delimiter = ',').load(\"abfss://.../mldata/MoviesDataRecommendation/ratings.csv\")\ndf.show()\n#import pandas as pd\n#data=pd.read_csv(\"/dbfs/FileStore/df_ratings.csv\", header='infer')\n## Convert Pandas dataframe to spark DataFrame\n#df = spark.createDataFrame(data)\n\n\n# top k items to recommend\nTOP_K = 10 \nCOL_USER = \"userId\"\nCOL_ITEM = \"movieId\"\nCOL_RATING = \"rating\"\nCOL_PREDICTION = \"rating\"\nCOL_TIMESTAMP = \"timestamp\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"1. Read Data","showTitle":true,"inputWidgets":{},"nuid":"8f9aff3a-257e-4a10-afdd-1e93de0f087f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+-------+------+----------+\n|userId|movieId|rating| timestamp|\n+------+-------+------+----------+\n|     1|    296|   5.0|1147880044|\n|     1|    306|   3.5|1147868817|\n|     1|    307|   5.0|1147868828|\n|     1|    665|   5.0|1147878820|\n|     1|    899|   3.5|1147868510|\n|     1|   1088|   4.0|1147868495|\n|     1|   1175|   3.5|1147868826|\n|     1|   1217|   3.5|1147878326|\n|     1|   1237|   5.0|1147868839|\n|     1|   1250|   4.0|1147868414|\n|     1|   1260|   3.5|1147877857|\n|     1|   1653|   4.0|1147868097|\n|     1|   2011|   2.5|1147868079|\n|     1|   2012|   2.5|1147868068|\n|     1|   2068|   2.5|1147869044|\n|     1|   2161|   3.5|1147868609|\n|     1|   2351|   4.5|1147877957|\n|     1|   2573|   4.0|1147878923|\n|     1|   2632|   5.0|1147878248|\n|     1|   2692|   5.0|1147869100|\n+------+-------+------+----------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-------+------+----------+\nuserId|movieId|rating| timestamp|\n+------+-------+------+----------+\n     1|    296|   5.0|1147880044|\n     1|    306|   3.5|1147868817|\n     1|    307|   5.0|1147868828|\n     1|    665|   5.0|1147878820|\n     1|    899|   3.5|1147868510|\n     1|   1088|   4.0|1147868495|\n     1|   1175|   3.5|1147868826|\n     1|   1217|   3.5|1147878326|\n     1|   1237|   5.0|1147868839|\n     1|   1250|   4.0|1147868414|\n     1|   1260|   3.5|1147877857|\n     1|   1653|   4.0|1147868097|\n     1|   2011|   2.5|1147868079|\n     1|   2012|   2.5|1147868068|\n     1|   2068|   2.5|1147869044|\n     1|   2161|   3.5|1147868609|\n     1|   2351|   4.5|1147877957|\n     1|   2573|   4.0|1147878923|\n     1|   2632|   5.0|1147878248|\n     1|   2692|   5.0|1147869100|\n+------+-------+------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# BinaryType: binary\n# BooleanType: boolean\n# ByteType: tinyint\n# DateType: date\n# DecimalType: decimal(10,0)\n# DoubleType: double\n# FloatType: float\n# IntegerType: int\n# LongType: bigint\n# ShortType: smallint\n# StringType: string\n# TimestampType: timestamp\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.sql.types import TimestampType\ndf = df.withColumn(\"userId\", df[\"userId\"].cast(\"int\"))\ndf = df.withColumn(\"movieId\", df[\"movieId\"].cast(\"int\"))\ndf = df.withColumn(\"rating\", df[\"rating\"].cast(\"double\"))\ndf = df.withColumn(\"timestamp\", df[\"timestamp\"].cast(\"timestamp\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e190e8a8-6736-44f2-98d7-0d0ff8291154"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["''' 1.Random split\nRandom split simply takes in a data set and outputs the splits of the data, given the split ratios.\n'''\ntrain, test = spark_random_split(df, ratio=0.70, seed=123)\nprint(\"Size of Train: \",train.cache().count())\nprint(\"Size of Validate: \",test.cache().count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"2. Split Data","showTitle":true,"inputWidgets":{},"nuid":"0c3a05ef-bb42-4133-9dee-41e59ead4f65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Size of Train:  17502121\nSize of Validate:  7497974\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Size of Train:  17502121\nSize of Validate:  7497974\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Modelling\n'''\nParameters:\n- numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10).\n- rank is the number of latent factors in the model (defaults to 10).\n- maxIter is the maximum number of iterations to run (defaults to 10).\n- regParam specifies the regularization parameter in ALS (defaults to 1.0).\n- implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n- alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0).\n- nonnegative specifies whether or not to use nonnegative constraints for least squares (defaults to false).\n'''\n\nheader = {\n    \"userCol\": COL_USER,\n    \"itemCol\": COL_ITEM,\n    \"ratingCol\": COL_RATING,\n}\n\n\nals = ALS(\n    rank=10,\n    maxIter=15,\n    implicitPrefs=False,\n    regParam=0.05,\n    coldStartStrategy='drop',\n    nonnegative=False,\n    seed=42,\n    **header\n)\nmodel = als.fit(train)\n\n\n#Scoring\n#In the movie recommendation use case, recommending movies that have been rated by the users do not make sense. Therefore, the rated movies are removed from the recommended items.In order to achieve this, we recommend all movies to all users, and then remove the user-movie pairs that exist in the training dataset.\n\n# Get the cross join of all user-item pairs and score them.\nusers = train.select(COL_USER).distinct()\nitems = train.select(COL_ITEM).distinct()\nuser_item = users.crossJoin(items)\ndfs_pred = model.transform(user_item) #scoring using the model trained\n\n# Remove seen items.\nspark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")\nspark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\ndfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n    train.alias(\"train\"),\n    (dfs_pred[COL_USER] == train[COL_USER]) & (dfs_pred[COL_ITEM] == train[COL_ITEM]),\n    how='outer'\n)\n\ntop_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[f\"train.{COL_RATING}\"].isNull()) \\\n    .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n\ntop_all.cache().count()\ntop_all.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"3. Train the ALS model on the training data, and get the top-k recommendations for our testing data","showTitle":true,"inputWidgets":{},"nuid":"5be06ffc-e30c-459b-aacf-2334e5581359"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+-------+----------+\n|userId|movieId|prediction|\n+------+-------+----------+\n|     1|    587| 2.6998122|\n|     1|    869| 2.9099126|\n|     1|   1208| 4.0218315|\n|     1|   1348| 3.5810237|\n|     1|   1357|  3.883794|\n|     1|   1677| 2.7238045|\n|     1|   1702| 1.7985499|\n|     1|   1720| 1.4157087|\n|     1|   1892| 3.0486994|\n|     1|   2086| 2.6992016|\n|     1|   2202|  3.520183|\n|     1|   2324|  4.223861|\n|     1|   2483| 3.3862746|\n|     1|   2545| 3.8411288|\n|     1|   2667|  1.291569|\n|     1|   2870| 3.2438471|\n|     1|   3304| 3.8208761|\n|     1|   3452| 2.5336146|\n|     1|   3468| 3.8727543|\n|     1|   3477| 3.4407997|\n+------+-------+----------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-------+----------+\nuserId|movieId|prediction|\n+------+-------+----------+\n     1|    587| 2.6998122|\n     1|    869| 2.9099126|\n     1|   1208| 4.0218315|\n     1|   1348| 3.5810237|\n     1|   1357|  3.883794|\n     1|   1677| 2.7238045|\n     1|   1702| 1.7985499|\n     1|   1720| 1.4157087|\n     1|   1892| 3.0486994|\n     1|   2086| 2.6992016|\n     1|   2202|  3.520183|\n     1|   2324|  4.223861|\n     1|   2483| 3.3862746|\n     1|   2545| 3.8411288|\n     1|   2667|  1.291569|\n     1|   2870| 3.2438471|\n     1|   3304| 3.8208761|\n     1|   3452| 2.5336146|\n     1|   3468| 3.8727543|\n     1|   3477| 3.4407997|\n+------+-------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#train.where((train.userId==1) & (train.movieId==1348)).show()\n#These are already avaialble in data as rated, so excluded from the top_all. Only predicted values of rating for user/movies not avaialble in training set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5c91e5a-9639-4a31-a6e0-55dc2c4829b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+-------+------+---------+\n|userId|movieId|rating|timestamp|\n+------+-------+------+---------+\n|     1|    296|   5.0|     null|\n|     1|    306|   3.5|     null|\n|     1|    307|   5.0|     null|\n|     1|    665|   5.0|     null|\n|     1|    899|   3.5|     null|\n|     1|   1088|   4.0|     null|\n|     1|   1175|   3.5|     null|\n|     1|   1217|   3.5|     null|\n|     1|   1237|   5.0|     null|\n|     1|   1250|   4.0|     null|\n|     1|   1260|   3.5|     null|\n|     1|   1653|   4.0|     null|\n|     1|   2011|   2.5|     null|\n|     1|   2012|   2.5|     null|\n|     1|   2068|   2.5|     null|\n|     1|   2161|   3.5|     null|\n|     1|   2351|   4.5|     null|\n|     1|   2573|   4.0|     null|\n|     1|   2632|   5.0|     null|\n|     1|   2692|   5.0|     null|\n+------+-------+------+---------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-------+------+---------+\nuserId|movieId|rating|timestamp|\n+------+-------+------+---------+\n     1|    296|   5.0|     null|\n     1|    306|   3.5|     null|\n     1|    307|   5.0|     null|\n     1|    665|   5.0|     null|\n     1|    899|   3.5|     null|\n     1|   1088|   4.0|     null|\n     1|   1175|   3.5|     null|\n     1|   1217|   3.5|     null|\n     1|   1237|   5.0|     null|\n     1|   1250|   4.0|     null|\n     1|   1260|   3.5|     null|\n     1|   1653|   4.0|     null|\n     1|   2011|   2.5|     null|\n     1|   2012|   2.5|     null|\n     1|   2068|   2.5|     null|\n     1|   2161|   3.5|     null|\n     1|   2351|   4.5|     null|\n     1|   2573|   4.0|     null|\n     1|   2632|   5.0|     null|\n     1|   2692|   5.0|     null|\n+------+-------+------+---------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["rank_eval = SparkRankingEvaluation(test, top_all, k = TOP_K, col_user=COL_USER, col_item=COL_ITEM, \n                                    col_rating=COL_RATING, col_prediction=\"prediction\", \n                                    relevancy_method=\"top_k\")\nprint(\"Model:\\tALS\",\n      \"Top K:\\t%d\" % rank_eval.k,\n      \"MAP:\\t%f\" % rank_eval.map_at_k(),\n      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"4.a. Evaluate how well ALS performs","showTitle":true,"inputWidgets":{},"nuid":"7e9b89fd-11fa-4865-ada3-bf9acf4d954c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Model:\tALS\nTop K:\t10\nMAP:\t0.000000\nNDCG:\t0.000024\nPrecision@K:\t0.000022\nRecall@K:\t0.000002\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model:\tALS\nTop K:\t10\nMAP:\t0.000000\nNDCG:\t0.000024\nPrecision@K:\t0.000022\nRecall@K:\t0.000002\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Generate predicted ratings.\n\n#prediction v/s original rating in test dataframe\nprediction = model.transform(test)\nprediction.cache().show()\n\nrating_eval = SparkRatingEvaluation(test, prediction, col_user=COL_USER, col_item=COL_ITEM, \n                                    col_rating=COL_RATING, col_prediction=\"prediction\")\n\nprint(\"Model:\\tALS rating prediction\",\n      \"RMSE:\\t%f\" % rating_eval.rmse(),\n      \"MAE:\\t%f\" % rating_eval.mae(),\n      \"Explained variance:\\t%f\" % rating_eval.exp_var(),\n      \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n')\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"4.b. Evaluate 'rating' predictions ","showTitle":true,"inputWidgets":{},"nuid":"6ed8a502-54dd-455b-a5f1-097edeab0aff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+-------+------+---------+----------+\n|userId|movieId|rating|timestamp|prediction|\n+------+-------+------+---------+----------+\n|  3411|    148|   3.0|     null| 3.1010756|\n| 31376|    148|   2.0|     null|  2.487941|\n|138552|    148|   4.0|     null| 3.3528645|\n| 73925|    148|   2.5|     null| 2.8853617|\n| 18628|    148|   2.0|     null| 2.5358372|\n| 91345|    148|   3.0|     null| 2.5081975|\n|136364|    148|   4.0|     null| 3.1493373|\n|110365|    148|   4.0|     null|  2.788095|\n|153108|    148|   1.0|     null| 2.5116093|\n|122236|    148|   2.5|     null| 2.4000401|\n|140907|    148|   4.0|     null| 2.5808144|\n|153916|    148|   3.0|     null| 2.9606023|\n| 25467|    148|   3.0|     null|  2.400282|\n| 32268|    148|   4.0|     null| 2.9746733|\n| 38679|    148|   3.0|     null|   2.53785|\n| 99684|    148|   3.0|     null| 2.9070284|\n|108767|    148|   3.0|     null| 2.6903741|\n|157307|    148|   3.0|     null| 2.7582307|\n| 66358|    148|   3.5|     null|   2.92726|\n| 81091|    148|   1.0|     null|   2.54278|\n+------+-------+------+---------+----------+\nonly showing top 20 rows\n\nModel:\tALS rating prediction\nRMSE:\t0.791485\nMAE:\t0.606727\nExplained variance:\t0.450670\nR squared:\t0.443385\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-------+------+---------+----------+\nuserId|movieId|rating|timestamp|prediction|\n+------+-------+------+---------+----------+\n  3411|    148|   3.0|     null| 3.1010756|\n 31376|    148|   2.0|     null|  2.487941|\n138552|    148|   4.0|     null| 3.3528645|\n 73925|    148|   2.5|     null| 2.8853617|\n 18628|    148|   2.0|     null| 2.5358372|\n 91345|    148|   3.0|     null| 2.5081975|\n136364|    148|   4.0|     null| 3.1493373|\n110365|    148|   4.0|     null|  2.788095|\n153108|    148|   1.0|     null| 2.5116093|\n122236|    148|   2.5|     null| 2.4000401|\n140907|    148|   4.0|     null| 2.5808144|\n153916|    148|   3.0|     null| 2.9606023|\n 25467|    148|   3.0|     null|  2.400282|\n 32268|    148|   4.0|     null| 2.9746733|\n 38679|    148|   3.0|     null|   2.53785|\n 99684|    148|   3.0|     null| 2.9070284|\n108767|    148|   3.0|     null| 2.6903741|\n157307|    148|   3.0|     null| 2.7582307|\n 66358|    148|   3.5|     null|   2.92726|\n 81091|    148|   1.0|     null|   2.54278|\n+------+-------+------+---------+----------+\nonly showing top 20 rows\n\nModel:\tALS rating prediction\nRMSE:\t0.791485\nMAE:\t0.606727\nExplained variance:\t0.450670\nR squared:\t0.443385\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2.c. Modelling- ALS (Collaborative)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{"EnvType":{"nuid":"7bf6016b-8f96-4f96-a009-93a650467879","currentValue":"DEV","widgetInfo":{"widgetType":"text","name":"EnvType","defaultValue":"DEV","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":1153725985288640}},"nbformat":4,"nbformat_minor":0}
